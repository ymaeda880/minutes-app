# -*- coding: utf-8 -*-
# pages/12_é‡è¤‡ç®‡æ‰€æ¤œå‡º3.py
#
# å¾ŒåŠã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ã€Œæœ€åˆã®æ•°è¡Œã€ã‚’ã‚­ãƒ¼ã«ã€
# å‰åŠã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ã€Œæœ€å¾Œã®2åˆ†ç›¸å½“ï¼ˆæ–‡å­—æ•°ï¼‰ã€ã®ä¸­ã‹ã‚‰
# ã‚‚ã£ã¨ã‚‚ã‚ˆãä¸€è‡´ã™ã‚‹ä½ç½®ã‚’æ¢ã—ã€
# å‰åŠå´ã«ã ã‘ã€Œ-----ã“ã“ã‹ã‚‰é‡è¤‡-----ã€ã‚’æŒ¿å…¥ã™ã‚‹ã€‚
#
# å¾ŒåŠå´ã«ã¯ã€Œã“ã“ã¾ã§ãŒé‡è¤‡éƒ¨åˆ†ã€ã¯å…¥ã‚Œãªã„ã€‚

from __future__ import annotations

import re
from difflib import SequenceMatcher
from typing import List, Dict, Tuple

import streamlit as st

# ============================================================
# è¨­å®šå€¤
# ============================================================

# ã€Œå‰å¾Œã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®æ¯”è¼ƒç¯„å›²ã€ï¼ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—é•·ï¼ˆå‰åŠã®æœ€å¾Œã®ä½•æ–‡å­—ã‚’è¦‹ã‚‹ã‹ï¼‰
OVERLAP_CHARS = 700  # ãŠãŠã‚ˆã2åˆ†ç›¸å½“ã®ç›®å®‰

# ã€Œå¾ŒåŠã®æœ€åˆã®æ•°è¡Œã€ã¨ã—ã¦ä½¿ã†æœ€å¤§æ–‡å­—æ•°
HEAD_CHARS = 400

# ã€Œå¾ŒåŠã®æœ€åˆã®æ•°è¡Œã€ã¨ã—ã¦åŒºåˆ‡ã‚‹æœ€å¤§æ–‡æ•°
HEAD_SENTENCES = 3

# ä¸€è‡´ã¨ã¿ãªã™æœ€ä½æ–‡å­—æ•°
MIN_MATCH_SIZE = 15

# å¢ƒç•Œãƒãƒ¼ã‚«ãƒ¼è¡Œ
MARKER_PATTERN = re.compile(
    r"^-{3,}\s*ã“ã“ãŒã¤ãªãç›®ã§ã™ï¼ˆ(.*?)ï¼‰.*$",
    re.MULTILINE,
)

BEGIN_TAG = "-----ã“ã“ã‹ã‚‰é‡è¤‡-----"


# ============================================================
# ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†å‰²
# ============================================================

def split_by_markers(text: str) -> Tuple[List[str], List[Dict[str, str]]]:
    """
    å…¨æ–‡ã‹ã‚‰ã€Œã¤ãªãç›®ãƒãƒ¼ã‚«ãƒ¼è¡Œã€ã§åˆ†å‰²ã—ã¦
    segments ã¨ markers ã‚’è¿”ã™ã€‚

    [seg0][marker0][seg1][marker1][seg2]...
    â†’ segments = [seg0, seg1, seg2, ...]
      markers  = [marker0, marker1, ...]
    """
    segments: List[str] = []
    markers: List[Dict[str, str]] = []

    prev_end = 0

    for m in MARKER_PATTERN.finditer(text):
        seg = text[prev_end:m.start()]
        segments.append(seg)

        markers.append(
            {
                "file_name": m.group(1),
                "marker_text": m.group(0),
            }
        )
        prev_end = m.end()

    segments.append(text[prev_end:])
    return segments, markers


# ============================================================
# ã€Œå¾ŒåŠã®æœ€åˆã®æ•°è¡Œã€ã‚’æŠœãå‡ºã™
# ============================================================

def extract_head_phrase(next_seg: str) -> str:
    """
    å¾ŒåŠã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‹ã‚‰ã€Œæœ€åˆã®æ•°è¡Œã€ã‚’å–ã‚Šå‡ºã™ã€‚

    - å…ˆé ­ HEAD_CHARS æ–‡å­—ã‚’å¯¾è±¡
    - ãã®ä¸­ã§ã€Œã€‚ã€ã€Œï¼Ÿã€ã€Œï¼ã€ã€Œæ”¹è¡Œã€ã‚’æ–‡ã®åŒºåˆ‡ã‚Šã¨ã¿ãªã—ã€
      HEAD_SENTENCES æ–‡ã¾ã§å«ã‚ãŸéƒ¨åˆ†ã‚’ head_phrase ã¨ã—ã¦è¿”ã™ã€‚
    """
    if not next_seg:
        return ""

    s = next_seg[:HEAD_CHARS]
    count = 0
    end = len(s)

    for i, ch in enumerate(s):
        if ch in "ã€‚ï¼Ÿï¼\n":
            count += 1
            if count >= HEAD_SENTENCES:
                end = i + 1  # åŒºåˆ‡ã‚Šè¨˜å·ã‚‚å«ã‚ã‚‹
                break

    return s[:end]


# ============================================================
# é‡è¤‡é–‹å§‹ä½ç½®ã®æ¢ç´¢ï¼ˆå‰åŠå´ã®ã¿ï¼‰
# ============================================================

# ============================================================
# é‡è¤‡é–‹å§‹ä½ç½®ã®æ¢ç´¢ï¼ˆå‰åŠå´ã®ã¿ï¼‰
# ============================================================

# æ­£è¦åŒ–ï¼šå¥èª­ç‚¹ãƒ»æ”¹è¡Œãƒ»ã‚¹ãƒšãƒ¼ã‚¹é™¤å»ï¼ˆå¿…è¦ãªã‚‰ã•ã‚‰ã«è¿½åŠ å¯ï¼‰
def normalize_text(s: str) -> str:
    # å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ â†’ ç©º
    s = s.replace("ã€€", "")
    # æ”¹è¡Œ â†’ ç©º
    s = s.replace("\n", "")
    # å¥èª­ç‚¹ãƒ»è¨˜å·ã‚’é™¤å»
    s = re.sub(r"[ã€ã€‚ï¼ï¼Ÿ,.!?]", "", s)
    # ä½™åˆ†ãªã‚¹ãƒšãƒ¼ã‚¹é™¤å»
    s = s.replace(" ", "")
    return s


SIMILARITY_THRESHOLD = 0.75  # é¡ä¼¼åº¦ã—ãã„å€¤ï¼ˆ0ã€œ1ï¼‰


def is_similar(a: str, b: str, threshold: float = SIMILARITY_THRESHOLD) -> bool:
    """2ã¤ã®æ–‡å­—åˆ—ã®é¡ä¼¼åº¦ãŒã—ãã„å€¤ä»¥ä¸Šã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
    return SequenceMatcher(None, a, b).ratio() >= threshold


def find_overlap_start(prev_seg: str, next_seg: str) -> Tuple[int, int]:
    """
    æ”¹è‰¯ç‰ˆï¼š
      - MIN_MATCH_SIZE = 20 ã«å¤‰æ›´ï¼ˆæ­£è¦åŒ–å¾Œ head ã®æœ€ä½é•·ãƒã‚§ãƒƒã‚¯ç”¨ï¼‰
      - æ­£è¦åŒ–ã—ãŸ head_phrase ã¨ prev_tail ã§ã‚¹ãƒ©ã‚¤ãƒ‰ã—ãªãŒã‚‰é¡ä¼¼åº¦ã‚’è¨ˆç®—
      - é¡ä¼¼åº¦ãŒ SIMILARITY_THRESHOLD ä»¥ä¸Šã§æœ€å¤§ã®ä½ç½®ã‚’é‡è¤‡é–‹å§‹ã¨ã¿ãªã™
      - ãã®ä½ç½®ã‚’å…ƒã®éæ­£è¦åŒ–ãƒ†ã‚­ã‚¹ãƒˆã® index ã«æˆ»ã—ã¦è¿”ã™
    """

    if not prev_seg or not next_seg:
        return -1, 0

    from_head = extract_head_phrase(next_seg)
    if not from_head:
        return -1, 0

    # å‰åŠå´ã®æœ«å°¾
    prev_tail = prev_seg[-OVERLAP_CHARS:]

    # æ­£è¦åŒ–ãƒ†ã‚­ã‚¹ãƒˆä½œæˆ
    norm_head = normalize_text(from_head)
    norm_prev = normalize_text(prev_tail)

    # head å´ãŒçŸ­ã™ãã‚‹å ´åˆã¯åˆ¤å®šã—ãªã„
    if len(norm_head) < MIN_MATCH_SIZE:
        return -1, 0

    # ======== æ­£è¦åŒ–ãƒ†ã‚­ã‚¹ãƒˆä¸Šã§ã®æœ€è‰¯ä½ç½®ã‚’æ¢ç´¢ï¼ˆã‚¹ãƒ©ã‚¤ãƒ‰çª“ï¼‰ ========
    Lh = len(norm_head)
    if len(norm_prev) < Lh:
        return -1, 0

    best_score = 0.0
    best_b_norm = -1

    for b_norm in range(0, len(norm_prev) - Lh + 1):
        window = norm_prev[b_norm:b_norm + Lh]
        score = SequenceMatcher(None, norm_head, window).ratio()
        if score > best_score:
            best_score = score
            best_b_norm = b_norm

    # é¡ä¼¼åº¦ãŒã—ãã„å€¤ã‚’ä¸‹å›ã‚‹ãªã‚‰é‡è¤‡ãªã—
    if best_b_norm < 0 or best_score < SIMILARITY_THRESHOLD:
        return -1, 0

    # ======== å…ƒãƒ†ã‚­ã‚¹ãƒˆã® index ã«æˆ»ã™ãŸã‚ã®å‡¦ç† ========

    def build_index_map(raw: str, norm: str):
        """
        æ­£è¦åŒ–å‰ raw ã®å„æ–‡å­—ãŒã€æ­£è¦åŒ–å¾Œ norm ã®
        ã©ã® index ã«å¯¾å¿œã™ã‚‹ã‹ã® map ã‚’ä½œã‚‹
        ï¼ˆnorm_idx â†’ raw_idx ã®å¯¾å¿œãƒšã‚¢ã®ãƒªã‚¹ãƒˆï¼‰
        """
        mapping: List[Tuple[int, int]] = []
        j = 0  # norm å´ã® index
        for i, ch in enumerate(raw):
            ch_norm = normalize_text(ch)
            if ch_norm == "":
                # æ­£è¦åŒ–ã§æ¶ˆãˆã‚‹æ–‡å­—ã¯ã‚¹ã‚­ãƒƒãƒ—
                continue
            if j < len(norm):
                mapping.append((j, i))
                j += 1
        return mapping

    head_map = build_index_map(from_head, norm_head)
    prev_map = build_index_map(prev_tail, norm_prev)

    def mapped_index(mapping: List[Tuple[int, int]], idx_norm: int) -> int:
        """
        æ­£è¦åŒ–å¾Œã® index ã‹ã‚‰ã€å¯¾å¿œã™ã‚‹ï¼ˆã¾ãŸã¯ä¸€ç•ªè¿‘ã„ï¼‰å…ƒãƒ†ã‚­ã‚¹ãƒˆã® index ã‚’å–å¾—
        """
        candidates = [raw_idx for norm_idx, raw_idx in mapping if norm_idx == idx_norm]
        if candidates:
            return candidates[0]

        # ç›´æ¥ä¸€è‡´ãŒãªã‘ã‚Œã°æœ€ã‚‚è¿‘ã„ norm_idx ã‚’æ¢ã™
        nearest = None
        best_dist = 10**9
        for norm_idx, raw_idx in mapping:
            d = abs(norm_idx - idx_norm)
            if d < best_dist:
                best_dist = d
                nearest = raw_idx
        return nearest if nearest is not None else 0

    # head å´ã¯ã€Œæ­£è¦åŒ–æ–‡å­—åˆ—ã®å…ˆé ­ã€ã‚’åŸºæº–ã«ã™ã‚‹
    head_raw_start = mapped_index(head_map, 0)
    # prev å´ã¯ã€Œæœ€è‰¯ä¸€è‡´çª“ã®å…ˆé ­ã€best_b_norm ã‚’åŸºæº–
    prev_raw_start = mapped_index(prev_map, best_b_norm)

    # ã€Œhead ã®å…ˆé ­ã¨ align ã™ã‚‹ã€å‰æã§è£œæ­£
    start_in_tail = max(0, prev_raw_start - head_raw_start)

    global_prev_start = len(prev_seg) - len(prev_tail) + start_in_tail

    # size ã¯ã‚ãã¾ã§å‚è€ƒå€¤ï¼ˆé¡ä¼¼åº¦ Ã— headé•·ï¼‰ã¨ã—ã¦è¿”ã™
    approx_size = int(len(norm_head) * best_score)

    return global_prev_start, approx_size

# ============================================================
# çµåˆå‡¦ç†ï¼ˆå‰åŠå´ã ã‘ãƒãƒ¼ã‚¯ï¼‰
# ============================================================

def build_merged_text(text: str) -> str:
    """
    ã¤ãªãç›®ã”ã¨ã«å‰åŠã‚»ã‚°ãƒ¡ãƒ³ãƒˆæœ«å°¾ã®é‡è¤‡é–‹å§‹ä½ç½®ã‚’æ¢ã—ã€
    ãã“ã«ã€Œ-----ã“ã“ã‹ã‚‰é‡è¤‡-----ã€ã‚’æŒ¿å…¥ã™ã‚‹ã€‚

    å¾ŒåŠã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¯ãã®ã¾ã¾ï¼ˆã€Œã“ã“ã¾ã§é‡è¤‡ã€ã¯ä»˜ã‘ãªã„ï¼‰ã€‚
    """
    segments, markers = split_by_markers(text)

    if len(segments) <= 1 or not markers:
        # ãƒãƒ¼ã‚«ãƒ¼ãŒãªã„å ´åˆã¯ãã®ã¾ã¾è¿”ã™
        return text

    merged: List[str] = []

    # æœ€åˆã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ä¸€æ—¦ãã®ã¾ã¾å…¥ã‚Œã¦ãŠã
    merged.append(segments[0])

    for idx, marker in enumerate(markers):
        prev_seg = segments[idx]
        next_seg = segments[idx + 1]

        # é‡è¤‡é–‹å§‹ä½ç½®ã‚’æ¢ç´¢
        start_pos, size = find_overlap_start(prev_seg, next_seg)

        if start_pos < 0 or size <= 0:
            # é‡è¤‡ãŒæ¤œå‡ºã§ããªã‹ã£ãŸå ´åˆï¼š
            #   ç›´å‰ã«å…¥ã‚Œã¦ã„ãŸå‰ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¯ãã®ã¾ã¾ã€
            #   ãƒãƒ¼ã‚«ãƒ¼ã¨å¾Œã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ãã®ã¾ã¾ç¹‹ã
            merged.append("\n" + marker["marker_text"] + "\n")
            merged.append(next_seg)
            continue

        # å‰åŠå´ã®é‡è¤‡é–‹å§‹ä½ç½®ã§ã‚¿ã‚°ã‚’æŒ¿å…¥ã—ãŸæ–°ã—ã„å‰ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ä½œã‚‹
        new_prev = (
            prev_seg[:start_pos]
            + "\n" + BEGIN_TAG + "\n"
            + prev_seg[start_pos:]
        )

        # ç›´å‰ã® merged[-1]ï¼ˆå¤ã„ prev_segï¼‰ã‚’å·®ã—æ›¿ãˆ
        merged[-1] = new_prev

        # ãƒãƒ¼ã‚«ãƒ¼è¡Œ
        merged.append("\n" + marker["marker_text"] + "\n")

        # å¾ŒåŠå´ã¯ä½•ã‚‚å‰Šã‚‰ãšã€ãã®ã¾ã¾ç¶šã‘ã‚‹
        merged.append(next_seg)

    return "".join(merged)


# ============================================================
# Streamlit UI
# ============================================================

st.set_page_config(
    page_title="ğŸ“ æ–‡å­—èµ·ã“ã—çµåˆï¼ˆé‡è¤‡æ¤œå‡ºï¼šå¾ŒåŠã®æœ€åˆã®æ•°è¡Œãƒ™ãƒ¼ã‚¹ï¼‰",
    page_icon="ğŸ“",
    layout="wide",
)

st.title("ğŸ“ é‡è¤‡ç®‡æ‰€æ¤œå‡ºï¼ˆå¾ŒåŠã®æœ€åˆã®æ•°è¡Œã‹ã‚‰é‡è¤‡é–‹å§‹ã‚’æ¤œå‡ºï¼‰")

st.markdown(
    """
- å¾ŒåŠã‚»ã‚°ãƒ¡ãƒ³ãƒˆã® **ã€Œæœ€åˆã®æ•°è¡Œã€** ã‚’ã‚­ãƒ¼ã«ã—ã¦ã€  
  å‰åŠã‚»ã‚°ãƒ¡ãƒ³ãƒˆã® **ã€Œæœ€å¾Œã®2åˆ†ç›¸å½“ã€** ã®ä¸­ã‹ã‚‰  
  ã‚‚ã£ã¨ã‚‚ã‚ˆãä¸€è‡´ã™ã‚‹ä½ç½®ã‚’æ¢ã—ã€å‰åŠå´ã«ã ã‘  
  `-----ã“ã“ã‹ã‚‰é‡è¤‡-----` ã‚’æŒ¿å…¥ã—ã¾ã™ã€‚

- å¾ŒåŠã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«ã¯ã€Œã“ã“ã¾ã§é‡è¤‡éƒ¨åˆ†ã€ã¯æŒ¿å…¥ã—ã¾ã›ã‚“ã€‚
"""
)

# ğŸ”½ ãƒ­ã‚¸ãƒƒã‚¯èª¬æ˜ï¼ˆåˆæœŸã¯ç•³ã‚“ã§ãŠãï¼‰
with st.expander("ğŸ” ã“ã®ãƒ„ãƒ¼ãƒ«ã®é‡è¤‡æ¤œå‡ºãƒ­ã‚¸ãƒƒã‚¯ï¼ˆæ¦‚è¦ï¼‰", expanded=False):
    st.markdown(
        """
1. **ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†å‰²**  
   - ãƒ†ã‚­ã‚¹ãƒˆå…¨ä½“ã‚’ã€Œ--- ã“ã“ãŒã¤ãªãç›®ã§ã™ï¼ˆâ€¦ï¼‰ã€ã¨ã„ã†ãƒãƒ¼ã‚«ãƒ¼è¡Œã§åˆ†å‰²ã—ã€  
     `[å‰åŠã‚»ã‚°ãƒ¡ãƒ³ãƒˆ][ãƒãƒ¼ã‚«ãƒ¼][å¾ŒåŠã‚»ã‚°ãƒ¡ãƒ³ãƒˆ]...` ã¨ã„ã†å½¢ã«åˆ†ã‘ã¾ã™ã€‚

2. **å¾ŒåŠå´ã®ã€Œæœ€åˆã®æ•°è¡Œã€ã‚’æŠ½å‡º**  
   - å„ã¤ãªãç›®ã«ã¤ã„ã¦ã€å¾ŒåŠã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®å…ˆé ­ã‹ã‚‰ `HEAD_CHARS` æ–‡å­—ã‚’å–ã‚Šå‡ºã—ã€  
     ã€Œã€‚ã€ã€Œï¼Ÿã€ã€Œï¼ã€ã€Œæ”¹è¡Œã€ãªã©ã§åŒºåˆ‡ã£ã¦ **æœ€å¤§ `HEAD_SENTENCES` æ–‡** ã¾ã§ã‚’  
     `head_phrase` ã¨ã—ã¦ä½¿ã„ã¾ã™ã€‚

3. **å‰åŠå´ã®ã€Œæœ€å¾Œã®2åˆ†ç›¸å½“ã€ã‚’å–å¾—**  
   - å‰åŠã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®æœ«å°¾ã‹ã‚‰ `OVERLAP_CHARS` æ–‡å­—ã ã‘ã‚’åˆ‡ã‚Šå‡ºã—ã€  
     ã“ã‚Œã‚’ `prev_tail` ã¨ã—ã¦æ¯”è¼ƒå¯¾è±¡ã«ã—ã¾ã™ã€‚

4. **æ­£è¦åŒ–ã—ã¦é¡ä¼¼åº¦ã‚’è¨ˆç®—**  
   - `head_phrase` ã¨ `prev_tail` ã‹ã‚‰  
     - å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹  
     - æ”¹è¡Œ  
     - å¥èª­ç‚¹ï¼ˆã€ã€‚ï¼ï¼Ÿ,.!?ï¼‰  
     - åŠè§’ã‚¹ãƒšãƒ¼ã‚¹  
     ã‚’å–ã‚Šé™¤ã„ãŸ **æ­£è¦åŒ–ãƒ†ã‚­ã‚¹ãƒˆ**ï¼ˆ`norm_head`, `norm_prev`ï¼‰ã‚’ä½œã‚Šã¾ã™ã€‚  
   - `norm_head` ãŒçŸ­ã™ãã‚‹å ´åˆã¯ï¼ˆ`MIN_MATCH_SIZE = 20` æœªæº€ï¼‰ãã®ã¤ãªãç›®ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚

5. **é¡ä¼¼åº¦ã—ãã„å€¤ã§æœ€è‰¯ã®é‡è¤‡ä½ç½®ã‚’æ¢ã™**  
   - `norm_head` ã®é•·ã•ã¨åŒã˜é•·ã•ã®ã€Œçª“ã€ã‚’ `norm_prev` ã®ä¸­ã§ã‚¹ãƒ©ã‚¤ãƒ‰ã•ã›ã€  
     å„ä½ç½®ã«ã¤ã„ã¦ `SequenceMatcher` ã® `ratio()` ã‚’ç”¨ã„ã¦ **é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢** ã‚’è¨ˆç®—ã—ã¾ã™ã€‚  
   - é¡ä¼¼åº¦ãŒã‚‚ã£ã¨ã‚‚é«˜ã„ä½ç½®ã‚’å–ã‚Šå‡ºã—ã€  
     ãã®ã‚¹ã‚³ã‚¢ãŒ `SIMILARITY_THRESHOLD`ï¼ˆä¾‹ï¼š0.82ï¼‰ä»¥ä¸Šã§ã‚ã‚Œã°ã€  
     **ã€Œã“ã“ã‹ã‚‰é‡è¤‡ã—ã¦ã„ã‚‹ã€ã¨åˆ¤å®š**ã—ã¾ã™ã€‚  
   - ã—ãã„å€¤æœªæº€ã§ã‚ã‚Œã°ã€ãã®ã¤ãªãç›®ã§ã¯é‡è¤‡ãªã—ã¨ã¿ãªã—ã¾ã™ã€‚

6. **æ­£è¦åŒ–å‰ã®ä½ç½®ã«ãƒãƒƒãƒ”ãƒ³ã‚°ã—ã¦ã‚¿ã‚°ã‚’æŒ¿å…¥**  
   - å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã¨æ­£è¦åŒ–ãƒ†ã‚­ã‚¹ãƒˆã®å¯¾å¿œé–¢ä¿‚ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒãƒƒãƒ—ï¼‰ã‚’ä½œã‚Šã€  
     æ­£è¦åŒ–ãƒ†ã‚­ã‚¹ãƒˆä¸Šã§è¦‹ã¤ã‹ã£ãŸä¸€è‡´é–‹å§‹ä½ç½®ã‚’ **å…ƒã®éæ­£è¦åŒ–ãƒ†ã‚­ã‚¹ãƒˆä¸Šã® index ã«æˆ»ã—ã¾ã™**ã€‚  
   - å‰åŠã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ãã®ä½ç½®ã«  
     `-----ã“ã“ã‹ã‚‰é‡è¤‡-----`  
     ã¨ã„ã†è¡Œã‚’æŒ¿å…¥ã—ã€å¾ŒåŠã‚»ã‚°ãƒ¡ãƒ³ãƒˆå´ã¯ä¸€åˆ‡å‰Šã‚‰ãšãã®ã¾ã¾é€£çµã—ã¾ã™ã€‚
        """
    )



uploaded_files = st.file_uploader(
    "æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆ (.txt) ã‚’ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—ã—ã¦ãã ã•ã„ï¼ˆè¤‡æ•°å¯ï¼‰",
    type=["txt"],
    accept_multiple_files=True,
)

run = st.button("â–¶ï¸ é‡è¤‡ç®‡æ‰€æ¤œå‡ºã‚’å®Ÿè¡Œã™ã‚‹", type="primary")

if run:
    if not uploaded_files:
        st.warning("å…ˆã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    else:
        for up in uploaded_files:
            name = up.name
            raw = up.read()
            try:
                text = raw.decode("utf-8")
            except UnicodeDecodeError:
                text = raw.decode("cp932", errors="replace")

            merged = build_merged_text(text)

            st.subheader(f"ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«: {name}")
            with st.expander("ğŸ“˜ çµæœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", expanded=True):
                st.text(merged)

            st.download_button(
                "ğŸ“¥ çµåˆãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (.txt)",
                merged.encode("utf-8"),
                file_name=f"{name.rsplit('.',1)[0]}_é‡è¤‡ç®‡æ‰€æ¤œå‡º.txt",
                mime="text/plain",
            )

        st.success("å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
