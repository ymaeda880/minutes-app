# ------------------------------------------------------------
# ğŸ™ï¸ è©±è€…åˆ†é›¢ãƒ»æ•´å½¢ï¼ˆè­°äº‹éŒ²ã®å‰å‡¦ç†ï¼‰â€” modernå°‚ç”¨ãƒ»ãƒªãƒˆãƒ©ã‚¤ãªã—ç‰ˆ
# - .txt ã‚’ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ— or è²¼ã‚Šä»˜ã‘
# - LLMã§è©±è€…æ¨å®šï¼ˆS1/S2/...ï¼‰ï¼‹ç™ºè©±ã”ã¨ã«æ”¹è¡Œãƒ»æ•´å½¢
# - GPT-5 ç³»åˆ—ã¯ temperature ã‚’å¤‰æ›´ä¸å¯ï¼ˆ=1å›ºå®šï¼‰â†’ UI ç„¡åŠ¹åŒ–ï¼†APIæœªé€ä¿¡
# - é•·æ–‡ï¼ˆ~2ä¸‡æ–‡å­—ï¼‰å¯¾å¿œï¼šmax_completion_tokens ã¯å¤§ãã‚ã«è¨­å®šã—ã¦ä¸€ç™ºå®Ÿè¡Œ
# - ç©ºå¿œç­”æ™‚ã¯ resp å…¨ä½“ã‚’ st.json ã§å‡ºã—ã¦ãƒ‡ãƒãƒƒã‚°
# - âœ… æ–™é‡‘è¨ˆç®—: lib.costs.estimate_chat_cost_usdï¼ˆconfig.MODEL_PRICES_USD å‚ç…§ï¼‰
# - âœ… ãƒˆãƒ¼ã‚¯ãƒ³å–å¾—: lib.tokens.extract_tokens_from_responseï¼ˆmodernå°‚ç”¨ï¼‰
# - âœ… ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†: lib/prompts.py ã®ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã«çµ±ä¸€
# - âœ… æ–‡å­—èµ·ã“ã—.py â†’ æœ¬ãƒšãƒ¼ã‚¸ã¸ã®è‡ªå‹•å¼•ãç¶™ãï¼‹å†èª­ã¿è¾¼ã¿ãƒœã‚¿ãƒ³ï¼ˆæœ¬ãƒ•ã‚¡ã‚¤ãƒ«ã§è¿½åŠ ï¼‰
# ------------------------------------------------------------
from __future__ import annotations

import time
from typing import Dict, Any

import streamlit as st
from openai import OpenAI

# ==== å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ====
from lib.costs import estimate_chat_cost_usd
from lib.tokens import extract_tokens_from_response, debug_usage_snapshot
from lib.prompts import SPEAKER_PREP, get_group, build_prompt
from config.config import DEFAULT_USDJPY
from ui.style import disable_heading_anchors

# ========================== å…±é€šè¨­å®š ==========================
st.set_page_config(page_title="â‘¢ è©±è€…åˆ†é›¢ãƒ»æ•´å½¢ï¼ˆæ–°ï¼‰", page_icon="ğŸ™ï¸", layout="wide")
disable_heading_anchors()
st.title("â‘¢ è©±è€…åˆ†é›¢ãƒ»æ•´å½¢ï¼ˆæ–°ï¼‰â€” è­°äº‹éŒ²ã®å‰å‡¦ç†")

OPENAI_API_KEY = st.secrets.get("openai", {}).get("api_key") or st.secrets.get("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    st.error("OpenAI API Key ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚.streamlit/secrets.toml ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

client = OpenAI(api_key=OPENAI_API_KEY)

# ===== æ–‡å­—èµ·ã“ã—ã‚¿ãƒ–ã‹ã‚‰ã®è‡ªå‹•å¼•ãç¶™ãï¼ˆåˆå›ã®ã¿ï¼‰ =====
# ã€Œæ–‡å­—èµ·ã“ã—.pyã€ã§ st.session_state["minutes_source_text"] ã«å…¥ã‚ŒãŸå†…å®¹ã‚’ã€
# æœ¬ãƒšãƒ¼ã‚¸ã®å…¥åŠ›æ¬„ï¼ˆprep_source_textï¼‰ã¸æœ€åˆã®1å›ã ã‘è‡ªå‹•åæ˜ ã—ã¾ã™ã€‚
if "prep_source_text_autofilled" not in st.session_state:
    st.session_state["prep_source_text_autofilled"] = False
if (not st.session_state["prep_source_text_autofilled"]) and st.session_state.get("minutes_source_text"):
    st.session_state["prep_source_text"] = st.session_state["minutes_source_text"]
    st.session_state["prep_source_text_autofilled"] = True
    st.session_state["from_transcribe_notice"] = True  # æ¬¡ã®UIã§ä¸€åº¦ã ã‘é€šçŸ¥

# ========================== ãƒ¢ãƒ‡ãƒ«è¨­å®šè£œåŠ© ==========================
def supports_temperature(model_name: str) -> bool:
    """GPT-5ç³»ã¯ temperature å¤‰æ›´ä¸å¯ï¼ˆ=1å›ºå®šï¼‰ã€‚"""
    return not model_name.startswith("gpt-5")

# ========================== UI ==========================
left, right = st.columns([1, 1], gap="large")

# ---- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ»UIï¼ˆlib/prompts ãƒ¬ã‚¸ã‚¹ãƒˆãƒªçµŒç”±ï¼‰ ----
with left:
    st.subheader("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")

    group = get_group(SPEAKER_PREP)

    # --- ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ– ---
    if "mandatory_prompt" not in st.session_state:
        st.session_state["mandatory_prompt"] = group.mandatory_default
    if "preset_label" not in st.session_state:
        st.session_state["preset_label"] = group.label_for_key(group.default_preset_key)
    if "preset_text" not in st.session_state:
        st.session_state["preset_text"] = group.body_for_label(st.session_state["preset_label"])
    if "extra_text" not in st.session_state:
        st.session_state["extra_text"] = ""

    mandatory = st.text_area(
        "å¿…ãšå…¥ã‚‹éƒ¨åˆ†ï¼ˆå¸¸ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å…ˆé ­ã«å«ã¾ã‚Œã¾ã™ï¼‰",
        height=220,
        key="mandatory_prompt",
    )

    def _on_change_preset():
        st.session_state["preset_text"] = group.body_for_label(st.session_state["preset_label"])

    st.selectbox(
        "è¿½è¨˜ãƒ—ãƒªã‚»ãƒƒãƒˆ",
        options=group.preset_labels(),
        index=group.preset_labels().index(st.session_state["preset_label"]),
        key="preset_label",
        help="é¸ã‚“ã å†…å®¹ãŒä¸Šã®å¿…é ˆæ–‡ã®ä¸‹ã«è‡ªå‹•çš„ã«é€£çµã•ã‚Œã¾ã™ã€‚",
        on_change=_on_change_preset,
    )

    preset_text = st.text_area("ï¼ˆç·¨é›†å¯ï¼‰ãƒ—ãƒªã‚»ãƒƒãƒˆæœ¬æ–‡", height=120, key="preset_text")
    extra = st.text_area("è¿½åŠ æŒ‡ç¤ºï¼ˆä»»æ„ï¼‰", height=88, key="extra_text")

    st.subheader("ãƒ¢ãƒ‡ãƒ«è¨­å®š")
    model = st.selectbox(
        "ãƒ¢ãƒ‡ãƒ«",
        [
            "gpt-5",
            "gpt-5-mini",
            "gpt-5-nano",
            "gpt-4.1-mini",
            "gpt-4.1",
        ],
        index=1,
    )

    temp_supported = supports_temperature(model)
    temperature = st.slider(
        "æ¸©åº¦ï¼ˆ0=å³æ ¼ / 2=è‡ªç”±ï¼‰",
        0.0, 2.0, value=1.0, step=0.1,
        disabled=not temp_supported,
        help="GPT-5 ç³»åˆ—ã¯ temperature=1 å›ºå®šã§ã™",
    )
    if not temp_supported:
        st.caption("â„¹ï¸ GPT-5 ç³»åˆ—ã¯ temperature ã‚’å¤‰æ›´ã§ãã¾ã›ã‚“ï¼ˆ=1å›ºå®šï¼‰")

    # å‡ºåŠ›ä¸Šé™ï¼ˆmodernå°‚ç”¨ï¼‰
    max_completion_tokens = st.slider(
        "æœ€å¤§å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆç›®å®‰ï¼‰",
        min_value=1000, max_value=40000, value=12000, step=500,
        help="2ä¸‡æ–‡å­—ç´šã®æ•´å½¢ãªã‚‰ 8,000ã€œ12,000 ç¨‹åº¦ã‚’æ¨å¥¨ï¼ˆæœ¬ç‰ˆã¯ãƒªãƒˆãƒ©ã‚¤ãªã—ï¼‰ã€‚",
    )

    st.subheader("é€šè²¨æ›ç®—ï¼ˆä»»æ„ï¼‰")
    usd_jpy = st.number_input("USD/JPY", min_value=50.0, max_value=500.0, value=float(DEFAULT_USDJPY), step=0.5)

    c1, c2 = st.columns(2)
    run_btn = c1.button("è©±è€…åˆ†é›¢ã—ã¦æ•´å½¢", type="primary", use_container_width=True)
    push_btn = c2.button("â• ã“ã®çµæœã‚’ã€â‘¡ è­°äº‹éŒ²ä½œæˆã€ã¸æ¸¡ã™", use_container_width=True)

with right:
    st.subheader("å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ")

    # è‡ªå‹•å–ã‚Šè¾¼ã¿é€šçŸ¥ï¼ˆ1å›ã ã‘ï¼‰
    if st.session_state.pop("from_transcribe_notice", False):
        st.success("âœ… ã€æ–‡å­—èµ·ã“ã—ã€ãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å—ã‘å–ã‚Šã¾ã—ãŸã€‚")

    # æ˜ç¤ºçš„ã«ã€Œæ–‡å­—èµ·ã“ã—ã‹ã‚‰å†èª­ã¿è¾¼ã¿ã€ã™ã‚‹ãƒœã‚¿ãƒ³
    reload_col, _ = st.columns([1, 3])
    if reload_col.button("â†© æ–‡å­—èµ·ã“ã—ã‹ã‚‰å†èª­ã¿è¾¼ã¿"):
        if st.session_state.get("minutes_source_text"):
            st.session_state["prep_source_text"] = st.session_state["minutes_source_text"]
            st.toast("æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’å†èª­ã¿è¾¼ã¿ã—ã¾ã—ãŸ", icon="âœ…")
        else:
            st.toast("èª­ã¿è¾¼ã‚ã‚‹æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚Šã¾ã›ã‚“", icon="âš ï¸")

    # .txt ãƒ‰ãƒ­ãƒƒãƒ— â†’ prep_source_text ã¸æ ¼ç´
    up = st.file_uploader("æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆï¼ˆ.txtï¼‰ã‚’ãƒ‰ãƒ­ãƒƒãƒ—", type=["txt"], accept_multiple_files=False)
    if up is not None:
        raw = up.read()
        try:
            text_from_file = raw.decode("utf-8")
        except UnicodeDecodeError:
            try:
                text_from_file = raw.decode("cp932")
            except Exception:
                text_from_file = raw.decode(errors="ignore")
        st.session_state["prep_source_text"] = text_from_file

    # ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ï¼ˆå„ªå…ˆ: prep_source_text â†’ æ¬¡ç‚¹: minutes_source_text â†’ ç©ºï¼‰
    src = st.text_area(
        "æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆï¼ˆè²¼ã‚Šä»˜ã‘å¯ï¼‰",
        value=st.session_state.get("prep_source_text", st.session_state.get("minutes_source_text", "")),
        height=420,
        placeholder="â‘ ãƒšãƒ¼ã‚¸ã®çµæœã‚’å¼•ãç¶™ãã‹ã€ã“ã“ã«è²¼ã‚Šä»˜ã‘ã‚‹ã‹ã€.txt ã‚’ãƒ‰ãƒ­ãƒƒãƒ—ã—ã¦ãã ã•ã„ã€‚",
        key="prep_source_text_area",
    )

# ========================== å®Ÿè¡Œï¼ˆãƒªãƒˆãƒ©ã‚¤ãªã—ä¸€ç™ºå®Ÿè¡Œï¼‰ ==========================
if run_btn:
    # ç›´è¿‘ã®ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢å†…å®¹ã‚’æœ€å„ªå…ˆã«ä½¿ç”¨
    src = st.session_state.get("prep_source_text", st.session_state.get("minutes_source_text", ""))

    if not src.strip():
        st.warning("æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆçµ„ã¿ç«‹ã¦
        combined = build_prompt(
            st.session_state["mandatory_prompt"],
            st.session_state["preset_text"],
            st.session_state["extra_text"],
            src,
        )

        def call_once(prompt_text: str, out_tokens: int):
            chat_kwargs: Dict[str, Any] = dict(
                model=model,
                messages=[{"role": "user", "content": prompt_text}],
                max_completion_tokens=int(out_tokens),
            )
            # GPT-5ç³»ã¯æ¸©åº¦å›ºå®šãªã®ã§é€ã‚‰ãªã„ã€‚ãã‚Œä»¥å¤–ã§1.0ã¨é•ã†æ™‚ã®ã¿é€ã‚‹ã€‚
            if supports_temperature(model) and abs(temperature - 1.0) > 1e-9:
                chat_kwargs["temperature"] = float(temperature)
            return client.chat.completions.create(**chat_kwargs)

        t0 = time.perf_counter()
        with st.spinner("è©±è€…åˆ†é›¢ãƒ»æ•´å½¢ã‚’å®Ÿè¡Œä¸­â€¦"):
            resp = call_once(combined, max_completion_tokens)

            text = ""
            finish_reason = None
            if resp and getattr(resp, "choices", None):
                # å‡ºåŠ›ãƒ†ã‚­ã‚¹ãƒˆã®å–ã‚Šå‡ºã—ï¼ˆãƒªãƒˆãƒ©ã‚¤ãªã—ï¼‰
                try:
                    text = resp.choices[0].message.content or ""
                except Exception:
                    text = getattr(resp.choices[0], "text", "")
                try:
                    finish_reason = resp.choices[0].finish_reason
                except Exception:
                    finish_reason = None

        elapsed = time.perf_counter() - t0

        if text.strip():
            st.markdown("### âœ… æ•´å½¢çµæœ")
            st.markdown(text)

            # === ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ & ã‚³ãƒ”ãƒ¼ ===
            import json
            base_filename = "speaker_prep_result"
            txt_bytes = text.encode("utf-8")

            dl_col, cp_col = st.columns([1, 1], gap="small")
            with dl_col:
                st.download_button(
                    "ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆï¼ˆ.txtï¼‰ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=txt_bytes,
                    file_name=f"{base_filename}.txt",
                    mime="text/plain",
                    use_container_width=True,
                )
            with cp_col:
                # ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã‚³ãƒ”ãƒ¼ï¼ˆClipboard APIï¼‰
                safe_json = json.dumps(text or "", ensure_ascii=False)
                st.components.v1.html(f"""
                <div style="display:flex;align-items:center;gap:.5rem">
                  <button id="copyBtn" style="width:100%;padding:.6rem 1rem;border-radius:.5rem;border:1px solid #e0e0e0;cursor:pointer">
                    ğŸ“‹ ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚³ãƒ”ãƒ¼
                  </button>
                  <span id="copyMsg" style="font-size:.9rem;color:#888"></span>
                </div>
                <script>
                  const content = {safe_json};
                  const btn = document.getElementById("copyBtn");
                  const msg = document.getElementById("copyMsg");
                  btn.addEventListener("click", async () => {{
                    try {{
                      await navigator.clipboard.writeText(content);
                      msg.textContent = "ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸ";
                      setTimeout(() => msg.textContent = "", 1600);
                    }} catch (e) {{
                      msg.textContent = "ã‚³ãƒ”ãƒ¼ã«å¤±æ•—";
                      setTimeout(() => msg.textContent = "", 1600);
                    }}
                  }});
                </script>
                """, height=60)
            # === è¿½åŠ ã“ã“ã¾ã§ ===

        else:
            st.warning("âš ï¸ ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ç©ºã®å¿œç­”ãŒè¿”ã•ã‚Œã¾ã—ãŸã€‚ãƒ¬ã‚¹ãƒãƒ³ã‚¹å…¨ä½“ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
            try:
                st.json(resp.model_dump())
            except Exception:
                st.write(resp)

        # === ãƒˆãƒ¼ã‚¯ãƒ³ç®—å‡ºï¼ˆmodernå°‚ç”¨ï¼‰ ===
        input_tok, output_tok, total_tok = extract_tokens_from_response(resp)

        # æ–™é‡‘è¦‹ç©ã‚Šï¼ˆmodernå°‚ç”¨: input/outputï¼‰
        usd = estimate_chat_cost_usd(model, input_tok, output_tok)
        jpy = (usd * usd_jpy) if usd is not None else None

        import pandas as pd
        metrics_data = {
            "å‡¦ç†æ™‚é–“": [f"{elapsed:.2f} ç§’"],
            "å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³": [f"{input_tok:,}"],
            "å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³": [f"{output_tok:,}"],
            "åˆè¨ˆãƒˆãƒ¼ã‚¯ãƒ³": [f"{total_tok:,}"],
            "æ¦‚ç®— (USD/JPY)": [f"${usd:,.6f} / Â¥{jpy:,.2f}" if usd is not None else "â€”"],
        }
        df_metrics = pd.DataFrame(metrics_data)
        st.subheader("ãƒˆãƒ¼ã‚¯ãƒ³ã¨æ–™é‡‘ã®æ¦‚è¦")
        st.table(df_metrics)

        # === ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šmodern usage ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ ===
        with st.expander("ğŸ” ãƒˆãƒ¼ã‚¯ãƒ³ç®—å‡ºã®å†…è¨³ï¼ˆmodern usage ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆï¼‰"):
            try:
                st.write(debug_usage_snapshot(getattr(resp, "usage", None)))
            except Exception as e:
                st.write({"error": str(e)})

        st.session_state["prep_last_output"] = text
        st.session_state["minutes_source_text"] = text  # â‘¡ è­°äº‹éŒ²ä½œæˆã‚¿ãƒ–ã¸æ¸¡ã™ç”¨

# ========================== å¼•ãæ¸¡ã—ï¼ˆãƒœã‚¿ãƒ³ï¼‰ ==========================
if push_btn:
    out = st.session_state.get("prep_last_output") or st.session_state.get("minutes_source_text", "")
    if not out.strip():
        st.warning("å…ˆã«ã€è©±è€…åˆ†é›¢ã—ã¦æ•´å½¢ã€ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    else:
        st.session_state["minutes_source_text"] = out
        st.success("æ•´å½¢çµæœã‚’ã€â‘¡ è­°äº‹éŒ²ä½œæˆã€ãƒšãƒ¼ã‚¸ã¸æ¸¡ã—ã¾ã—ãŸã€‚å·¦ã®ãƒŠãƒ“ã‹ã‚‰ç§»å‹•ã—ã¦ãã ã•ã„ã€‚")

# ========================== ãƒ˜ãƒ«ãƒ— ==========================
with st.expander("âš ï¸ é•·æ–‡å…¥åŠ›ï¼ˆ2ä¸‡æ–‡å­—å‰å¾Œï¼‰ã®æ³¨æ„ç‚¹"):
    st.markdown(
        """
- æ—¥æœ¬èª2ä¸‡æ–‡å­—ã¯ **ç´„1ä¸‡ã€œ1.5ä¸‡ãƒˆãƒ¼ã‚¯ãƒ³**ã§ã™ã€‚**gpt-4.1 ç³» / gpt-5 ç³»**ï¼ˆ128kã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼‰æ¨å¥¨ã€‚
- **max_completion_tokens** ã¯ 8000ã€œ12000 ç¨‹åº¦ãŒå®‰å…¨ã§ã™ï¼ˆæœ¬ç‰ˆã¯ãƒªãƒˆãƒ©ã‚¤ãªã—ã€‚å¿…è¦ã«å¿œã˜ã¦æœ€åˆã‹ã‚‰ååˆ†å¤§ããï¼‰ã€‚
- ä¾¡æ ¼è¡¨ã¯ `config.MODEL_PRICES_USD`ï¼ˆUSD/100ä¸‡ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰ã‚’é‹ç”¨ä¾¡æ ¼ã«åˆã‚ã›ã¦èª¿æ•´ã—ã¦ãã ã•ã„ã€‚
"""
    )
