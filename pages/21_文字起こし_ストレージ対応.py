# pages/21_æ–‡å­—èµ·ã“ã—_storageå¯¾å¿œ.py
# ============================================================
# ç›®çš„ï¼š
#   Storages/<user>/minutes_app/<YYYY-MM-DD>/<job_...>/split/ ã®ãƒãƒ£ãƒ³ã‚¯ã‚’é¸ã³ã€
#   OpenAI Transcribe / Whisper / GPT-4o Transcribe ã¾ãŸã¯ Gemini ã§é€£ç¶šæ–‡å­—èµ·ã“ã—ã€‚
#   çµæœã‚’ job é…ä¸‹ã® transcript/ ã«ä¿å­˜ï¼ˆå€‹åˆ¥ï¼‹combinedï¼‰ã€‚
#
# UI æ–¹é‡ï¼ˆåº·ç”·ã•ã‚“æŒ‡å®šï¼‰ï¼š
#   â‘ ã‚¸ãƒ§ãƒ–é¸æŠ â†’ ãƒ¡ã‚¤ãƒ³ï¼ˆä¸­å¤®ï¼‰
#   â‘¡ãƒãƒ£ãƒ³ã‚¯é¸æŠãƒ»å„ç¨®è¨­å®š â†’ ã‚µã‚¤ãƒ‰ãƒãƒ¼
#   å®Ÿè¡Œãƒœã‚¿ãƒ³ â†’ ãƒ¡ã‚¤ãƒ³ï¼ˆä½¿ã„ã‚„ã™ã•å„ªå…ˆï¼‰
#   çµæœè¡¨ç¤º â†’ ãƒ¡ã‚¤ãƒ³
# ============================================================

from __future__ import annotations

import io
import json
import re
import time
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import pandas as pd
import requests
from requests.adapters import HTTPAdapter, Retry
import streamlit as st
import shutil

from config.config import (
    # keys / endpoints
    get_openai_api_key,
    get_gemini_api_key,
    has_gemini_api_key,
    OPENAI_TRANSCRIBE_URL,
    # prices
    WHISPER_PRICE_PER_MIN,
    TRANSCRIBE_PRICES_USD_PER_MIN,
    DEFAULT_USDJPY,
    # gemini cost helpers
    estimate_tokens_from_text,
    estimate_gemini_cost_usd,
)

from lib.audio import get_audio_duration_seconds
from lib.explanation import render_transcribe_continuous_expander


# ============================================================
# sys.path èª¿æ•´ & ãƒ­ã‚°ã‚¤ãƒ³åˆ¤å®šï¼ˆå…±é€šï¼‰
# ============================================================
import sys

_THIS = Path(__file__).resolve()
PROJECTS_ROOT = _THIS.parents[3]
if str(PROJECTS_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECTS_ROOT))

from common_lib.storage.external_ssd_root import resolve_storage_subdir_root
from common_lib.auth.auth_helpers import require_login

# ============================================================
# Storage root
# ============================================================
STORAGE_ROOT = resolve_storage_subdir_root(
    PROJECTS_ROOT,
    subdir="Storages",
)

# ============================================================
# ãƒšãƒ¼ã‚¸è¨­å®š
# ============================================================
st.set_page_config(page_title="01 æ–‡å­—èµ·ã“ã— â€” Storage Jobs", layout="wide")

sub = require_login(st)
if not sub:
    st.stop()
left, right = st.columns([2, 1])
with left:
    st.title("æ–‡å­—èµ·ã“ã—ï¼ˆã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å¯¾å¿œ")
with right:
    st.success(f"âœ… ãƒ­ã‚°ã‚¤ãƒ³ä¸­: **{sub}**")
current_user=sub

render_transcribe_continuous_expander()

# ============================================================
# ãƒ­ã‚°ã‚¤ãƒ³
# ============================================================


# ============================================================
# ãƒ¦ãƒ¼ã‚¶ãƒ¼åã®ãƒ•ã‚©ãƒ«ãƒ€å®‰å…¨åŒ–ï¼ˆpages/20 ã¨åˆã‚ã›ã‚‹ï¼‰
# ============================================================
def _sanitize_username_for_path(username: str) -> str:
    u = (username or "").strip()
    if not u:
        return "anonymous"
    u = re.sub(r"[^0-9A-Za-z_-]+", "_", u).strip("_")
    return u or "anonymous"


USERNAME_DIR = _sanitize_username_for_path(str(current_user))
USER_ROOT = STORAGE_ROOT / USERNAME_DIR / "minutes_app"


# ============================================================
# OpenAI / Gemini ã‚­ãƒ¼
# ============================================================
OPENAI_API_KEY = get_openai_api_key()
if not OPENAI_API_KEY:
    st.error("OPENAI_API_KEY ãŒ .streamlit/secrets.toml ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop()

GEMINI_ENABLED = has_gemini_api_key()
GEMINI_API_KEY = get_gemini_api_key() if GEMINI_ENABLED else ""

# ============================================================
# ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–
# ============================================================
st.session_state.setdefault("usd_jpy", float(DEFAULT_USDJPY))
st.session_state.setdefault("model_last_valid", "whisper-1")
st.session_state.setdefault("model_picker", "whisper-1")
st.session_state.setdefault("gemini_disabled_notice", False)

# ============================================================
# ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç­‰
# ============================================================
BRACKET_TAG_PATTERN = re.compile(r"ã€[^ã€‘]*ã€‘")


def strip_bracket_tags(text: str) -> str:
    if not text:
        return text
    return BRACKET_TAG_PATTERN.sub("", text)


PROMPT_OPTIONS = [
    "",
    "å‡ºåŠ›ã«è©±è€…åã‚„ã€ã€‘ãªã©ã®ãƒ©ãƒ™ãƒ«ã‚’å…¥ã‚Œãªã„ã€‚éŸ³å£°ã«ç„¡ã„å˜èªã¯æ›¸ã‹ãªã„ã€‚",
    "äººåã‚„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã¯æ­£ç¢ºã«å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚å°‚é–€ç”¨èªã¯ã‚«ã‚¿ã‚«ãƒŠã§ã€‚",
    "å¥èª­ç‚¹ã‚’æ­£ã—ãä»˜ä¸ã—ã€è‡ªç„¶ãªæ–‡ç« ã«ã—ã¦ãã ã•ã„ã€‚",
]

MODEL_OPTIONS = [
    "whisper-1",
    "gpt-4o-mini-transcribe",
    "gpt-4o-transcribe",
    "gemini-2.0-flash",
]


def model_label(x: str) -> str:
    if x.startswith("gemini") and not GEMINI_ENABLED:
        return f"{x}ï¼ˆGEMINI_API_KEY æœªè¨­å®šï¼‰"
    return x


def on_change_model_picker():
    picked = st.session_state.get("model_picker", "whisper-1")
    if picked.startswith("gemini") and not GEMINI_ENABLED:
        st.session_state["gemini_disabled_notice"] = True
        st.session_state["model_picker"] = st.session_state.get("model_last_valid", "whisper-1")
    else:
        st.session_state["model_last_valid"] = picked
        st.session_state["gemini_disabled_notice"] = False


# ============================================================
# Job / split ã‚¹ã‚­ãƒ£ãƒ³
# ============================================================
AUDIO_EXTS = {".wav", ".mp3", ".m4a", ".mp4", ".webm", ".ogg"}


@dataclass
class JobInfo:
    date_dir: str
    job_id: str
    job_dir: Path
    split_dir: Path
    transcript_dir: Path
    transcript_marked_dir: Path
    logs_dir: Path
    job_json: Optional[dict]

    @property
    def label(self) -> str:
        base = f"{self.date_dir}/{self.job_id}"
        try:
            if self.job_json:
                orig = self.job_json.get("paths", {}).get("original")
                if orig:
                    return f"{base}  ï¼ˆoriginal: {Path(orig).name}ï¼‰"
        except Exception:
            pass
        return base


def safe_mkdir(p: Path) -> None:
    p.mkdir(parents=True, exist_ok=True)


def append_log(log_path: Path, msg: str) -> None:
    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    safe_mkdir(log_path.parent)
    with log_path.open("a", encoding="utf-8") as f:
        f.write(f"[{ts}] {msg}\n")


def read_json_if_exists(p: Path) -> Optional[dict]:
    if not p.exists():
        return None
    try:
        return json.loads(p.read_text(encoding="utf-8"))
    except Exception:
        return None


def scan_jobs(user_root: Path) -> List[JobInfo]:
    jobs: List[JobInfo] = []
    if not user_root.exists():
        return jobs

    for date_dir in sorted([d for d in user_root.iterdir() if d.is_dir()], reverse=True):
        for job_dir in sorted([j for j in date_dir.iterdir() if j.is_dir() and j.name.startswith("job_")], reverse=True):
            split_dir = job_dir / "split"
            transcript_dir = job_dir / "transcript"
            transcript_marked_dir = job_dir / "transcript_marked"
            logs_dir = job_dir / "logs"
            job_json = read_json_if_exists(job_dir / "job.json")

            jobs.append(
                JobInfo(
                    date_dir=date_dir.name,
                    job_id=job_dir.name,
                    job_dir=job_dir,
                    split_dir=split_dir,
                    transcript_dir=transcript_dir,
                    transcript_marked_dir=transcript_marked_dir,
                    logs_dir=logs_dir,
                    job_json=job_json,
                )
            )
    return jobs


def list_split_audio_files(split_dir: Path) -> List[Path]:
    if not split_dir.exists():
        return []
    out = []
    for p in sorted(split_dir.iterdir()):
        if p.is_file() and p.suffix.lower() in AUDIO_EXTS:
            out.append(p)
    return out


# ============================================================
# â‘  ã‚¸ãƒ§ãƒ–é¸æŠï¼ˆãƒ¡ã‚¤ãƒ³ï¼‰
# ============================================================
jobs_all = scan_jobs(USER_ROOT)

#
# å¤ã„ã‚¸ãƒ§ãƒ–ã‚’ç‰©ç†çš„ã«æ¶ˆå»
#
MAX_JOBS = 5
jobs_keep = jobs_all[:MAX_JOBS]
jobs_delete = jobs_all[MAX_JOBS:]

for j in jobs_delete:
    try:
        # job ãƒ•ã‚©ãƒ«ãƒ€å‰Šé™¤
        shutil.rmtree(j.job_dir)

        # â˜… è¿½åŠ ï¼šè¦ªã®æ—¥ä»˜ãƒ•ã‚©ãƒ«ãƒ€ãŒç©ºãªã‚‰å‰Šé™¤
        date_dir = j.job_dir.parent
        if date_dir.exists() and not any(date_dir.iterdir()):
            date_dir.rmdir()

    except Exception as e:
        st.warning(f"å‰Šé™¤å¤±æ•—: {j.job_dir} ({e})")

jobs = jobs_keep


#
# ã‚¸ãƒ§ãƒ–é¸æŠ
#
st.subheader("ã‚¸ãƒ§ãƒ–é¸æŠï¼ˆstorageï¼‰")
st.write("ç›´è¿‘ã®ï¼•ã¤ã®ã‚¸ãƒ§ãƒ–ã‚ˆã‚Šå¤ã„ã‚‚ã®ã¯è‡ªå‹•çš„ã«æ¶ˆå»ã•ã‚Œã¾ã™")

if not jobs:
    st.warning(f"ã‚¸ãƒ§ãƒ–ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {USER_ROOT}\nå…ˆã«ã€ŒéŸ³å£°åˆ†å‰²ï¼ˆstorageï¼‰ã€ã§ job ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
    st.stop()

job_labels = [j.label for j in jobs]
picked_label = st.radio(
    "å¯¾è±¡ã‚¸ãƒ§ãƒ–",
    options=job_labels,
    index=0,
    help="éŸ³å£°åˆ†å‰²ã§ä½œæˆã•ã‚ŒãŸ job ãƒ•ã‚©ãƒ«ãƒ€ã‚’é¸ã³ã¾ã™ï¼ˆsplit/ ã‚’å‚ç…§ï¼‰ã€‚",
)

picked_job = jobs[job_labels.index(picked_label)]

split_files = list_split_audio_files(picked_job.split_dir)
st.caption(f"é¸æŠä¸­ã® job: {picked_job.job_dir}")

if not split_files:
    st.warning("ã“ã® job ã«ã¯ split/ ã®éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    st.stop()

# ============================================================
# ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šâ‘¡ãƒãƒ£ãƒ³ã‚¯é¸æŠã€œâ‘¢é€šè²¨æ›ç®—ï¼ˆâ€»å®Ÿè¡Œãƒœã‚¿ãƒ³ã¯ãƒ¡ã‚¤ãƒ³ï¼‰
# ============================================================
with st.sidebar:
    st.header("ãƒãƒ£ãƒ³ã‚¯é¸æŠï¼ˆsplit/ï¼‰")

    options = [p.name for p in split_files]
    selected_names = st.multiselect(
        "å‡¦ç†ã™ã‚‹ãƒãƒ£ãƒ³ã‚¯ï¼ˆé¸æŠé †ã«é€£ç¶šæ–‡å­—èµ·ã“ã—ï¼‰",
        options=options,
        default=options,
    )

    st.divider()
    st.header("ãƒ¢ãƒ‡ãƒ«")
    st.radio(
        "ãƒ¢ãƒ‡ãƒ«",
        options=MODEL_OPTIONS,
        key="model_picker",
        format_func=model_label,
        on_change=on_change_model_picker,
    )

    if st.session_state.get("gemini_disabled_notice", False) and not GEMINI_ENABLED:
        st.warning("GEMINI_API_KEY ãŒæœªè¨­å®šã®ãŸã‚ã€Gemini ã¯é¸æŠã§ãã¾ã›ã‚“ã€‚")

    model = st.session_state["model_picker"]

    st.divider()
    st.header("è¿”å´å½¢å¼ãƒ»è¨€èªãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")
    fmt = st.selectbox("è¿”å´å½¢å¼ï¼ˆOpenAI response_formatï¼‰", ["json", "text", "srt", "vtt"], index=0)
    language = st.text_input("è¨€èªã‚³ãƒ¼ãƒ‰ï¼ˆæœªæŒ‡å®šãªã‚‰è‡ªå‹•åˆ¤å®šï¼‰", value="ja")
    prompt_hint = st.selectbox("Transcribeãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆçœç•¥å¯ï¼‰", options=PROMPT_OPTIONS, index=0)
    do_strip_brackets = st.checkbox("æ›¸ãèµ·ã“ã—å¾Œã«ã€â€¦ã€‘ã‚’é™¤å»ã™ã‚‹", value=True)

    st.divider()
    st.header("â‘¢ é€šè²¨æ›ç®—ï¼ˆä»»æ„ï¼‰")
    usd_jpy = st.number_input(
        "USD/JPY",
        min_value=50.0,
        max_value=500.0,
        value=float(st.session_state.get("usd_jpy", DEFAULT_USDJPY)),
        step=0.5,
    )
    st.session_state["usd_jpy"] = float(usd_jpy)

# ============================================================
# ãƒ¡ã‚¤ãƒ³ï¼šå®Ÿè¡Œãƒœã‚¿ãƒ³
# ============================================================
st.subheader("å®Ÿè¡Œ")
go = st.button("â–¶ï¸ æ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œï¼ˆé¸æŠé †ï¼‰+ ä¿å­˜", type="primary")

out_area = st.container()

def guess_mime(path: Path) -> str:
    suf = path.suffix.lower()
    if suf == ".mp3":
        return "audio/mpeg"
    if suf == ".wav":
        return "audio/wav"
    if suf == ".m4a":
        return "audio/mp4"
    if suf == ".mp4":
        return "video/mp4"
    if suf == ".webm":
        return "audio/webm"
    if suf == ".ogg":
        return "audio/ogg"
    return "application/octet-stream"


def save_text(p: Path, text: str) -> None:
    safe_mkdir(p.parent)
    p.write_text(text, encoding="utf-8")


# ============================================================
# å®Ÿè¡Œéƒ¨
# ============================================================
if go:
    if not selected_names:
        st.warning("ãƒãƒ£ãƒ³ã‚¯ã‚’1ã¤ä»¥ä¸Šé¸ã‚“ã§ãã ã•ã„ã€‚")
        st.stop()

    if model.startswith("gemini") and not GEMINI_ENABLED:
        st.error("GEMINI_API_KEY ãŒæœªè¨­å®šã®ãŸã‚ã€Gemini ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        st.stop()

    safe_mkdir(picked_job.transcript_dir)
    safe_mkdir(picked_job.transcript_marked_dir)  # æ¬¡å·¥ç¨‹ç”¨ï¼ˆ22ï¼‰
    safe_mkdir(picked_job.logs_dir)

    job_log_path = picked_job.logs_dir / "process.log"
    append_log(job_log_path, "TRANSCRIBE START")
    append_log(job_log_path, f"job={picked_job.job_dir}")
    append_log(job_log_path, f"model={model} fmt={fmt} language={language!r}")
    append_log(job_log_path, f"selected={selected_names}")

    headers = {"Authorization": f"Bearer {OPENAI_API_KEY}"}
    sess = requests.Session()
    retries = Retry(
        total=3,
        backoff_factor=1.2,
        status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=frozenset({"POST"}),
    )
    sess.mount("https://", HTTPAdapter(max_retries=retries))

    USE_GEMINI = model.startswith("gemini")
    if USE_GEMINI:
        import google.generativeai as genai
        genai.configure(api_key=GEMINI_API_KEY)
        gemini_model = genai.GenerativeModel(model)

    name_to_path = {p.name: p for p in split_files}
    targets = [name_to_path[n] for n in selected_names if n in name_to_path]

    progress = st.progress(0, text="æº–å‚™ä¸­â€¦")

    per_file_results: List[dict] = []
    combined_parts: List[str] = []
    total_elapsed = 0.0

    for idx, path in enumerate(targets, start=1):
        progress.progress((idx - 1) / len(targets), text=f"{idx}/{len(targets)} å‡¦ç†ä¸­: {path.name}")

        file_bytes = path.read_bytes()
        mime = guess_mime(path)

        audio_sec = audio_min = None
        try:
            audio_sec = get_audio_duration_seconds(io.BytesIO(file_bytes))
            audio_min = (audio_sec / 60.0) if audio_sec else None
        except Exception:
            pass

        t0 = time.perf_counter()

        if USE_GEMINI:
            instr_parts = [
                "ã“ã®éŸ³å£°ã‚’æ—¥æœ¬èªã§æ­£ç¢ºã«æ–‡å­—èµ·ã“ã—ã—ã¦ãã ã•ã„ã€‚",
                "æ—¥æœ¬èªã¯åˆ†ã‹ã¡æ›¸ãã«ã—ãªã„ã§ãã ã•ã„ï¼ˆå˜èªã®é–“ã«ä¸è¦ãªåŠè§’ã‚¹ãƒšãƒ¼ã‚¹ã‚’å…¥ã‚Œãªã„ï¼‰ã€‚",
                "å¥èª­ç‚¹ï¼ˆã€ã€‚ï¼‰ã‚’é©åˆ‡ã«è£œã„ã€è‡ªç„¶ãªæ–‡ç« ã¨ã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚",
            ]
            if language and language.strip():
                instr_parts.append(f"è¨€èªã‚³ãƒ¼ãƒ‰ã¯ {language.strip()} ã‚’å„ªå…ˆï¼ˆä¸æ˜ãªã‚‰è‡ªå‹•åˆ¤å®šï¼‰ã€‚")
            if prompt_hint and prompt_hint.strip():
                instr_parts.append(prompt_hint.strip())
            instruction = " ".join(instr_parts)

            with st.spinner(f"Gemini æ–‡å­—èµ·ã“ã—ä¸­â€¦ï¼ˆ{path.name}ï¼‰"):
                response = gemini_model.generate_content(
                    [
                        instruction,
                        {"mime_type": mime, "data": file_bytes},
                    ]
                )
            text = getattr(response, "text", "") or ""
            req_id = "gemini"
        else:
            files = {"file": (path.name, file_bytes, mime)}
            data: dict = {"model": model, "response_format": fmt}
            if prompt_hint and prompt_hint.strip():
                data["prompt"] = prompt_hint.strip()
            if language and language.strip():
                data["language"] = language.strip()

            with st.spinner(f"Transcribe API ã«é€ä¿¡ä¸­â€¦ï¼ˆ{path.name}ï¼‰"):
                resp = sess.post(
                    OPENAI_TRANSCRIBE_URL,
                    headers=headers,
                    files=files,
                    data=data,
                    timeout=600,
                )

            req_id = resp.headers.get("x-request-id")

            if not resp.ok:
                st.error(f"{path.name}: APIã‚¨ãƒ©ãƒ¼: {resp.status_code}\n{resp.text}\nrequest-id: {req_id}")
                append_log(job_log_path, f"ERROR {path.name} status={resp.status_code} req_id={req_id}")
                continue

            if fmt == "json":
                try:
                    text = resp.json().get("text", "")
                except Exception:
                    text = resp.text
            else:
                text = resp.text

        elapsed = time.perf_counter() - t0
        total_elapsed += elapsed

        if do_strip_brackets and text:
            text = strip_bracket_tags(text)

        usd = jpy = None
        in_tok = out_tok = None

        if USE_GEMINI:
            out_tok = estimate_tokens_from_text(text)
            in_tok = out_tok
            usd_est = estimate_gemini_cost_usd(model=model, input_tokens=in_tok, output_tokens=out_tok)
            if usd_est is not None:
                usd = float(usd_est)
                jpy = usd * float(st.session_state["usd_jpy"])
        else:
            if audio_min is not None:
                price_per_min = TRANSCRIBE_PRICES_USD_PER_MIN.get(model, WHISPER_PRICE_PER_MIN)
                usd = float(audio_min) * float(price_per_min)
                jpy = usd * float(st.session_state["usd_jpy"])

        # ä¿å­˜ï¼ˆå€‹åˆ¥ï¼‰
        out_txt = picked_job.transcript_dir / f"{idx:03d}_{path.stem}.txt"
        save_text(out_txt, text or "")
        append_log(job_log_path, f"SAVED transcript {path.name} -> {out_txt.name}")

        with out_area:
            st.markdown(f"### ğŸ“ {idx}. {path.name}")
            st.text_area("ãƒ†ã‚­ã‚¹ãƒˆï¼ˆå€‹åˆ¥ï¼‰", value=text, height=220, key=f"ta_{idx}")

            cost_str = "â€”"
            if usd is not None and jpy is not None:
                cost_str = f"${usd:,.6f} / Â¥{jpy:,.2f}"
            elif USE_GEMINI:
                cost_str = "â€”ï¼ˆGeminiï¼šãƒ¢ãƒ‡ãƒ«å˜ä¾¡æœªè¨­å®š or æ¨å®šä¸èƒ½ï¼‰"

            metrics_data = {
                "å‡¦ç†æ™‚é–“": [f"{elapsed:.2f} ç§’"],
                "éŸ³å£°é•·": [f"{audio_sec:.1f} ç§’ / {audio_min:.2f} åˆ†" if audio_sec else "â€”"],
                "æ¦‚ç®— (USD/JPY)": [cost_str],
                "æ¨å®štokens(in/out)": [f"{in_tok}/{out_tok}" if USE_GEMINI and in_tok is not None else "â€”"],
                "request-id": [req_id or "â€”"],
                "ãƒ¢ãƒ‡ãƒ«": [model],
                "ä¿å­˜å…ˆ": [str(out_txt)],
            }
            st.table(pd.DataFrame(metrics_data))

        per_file_results.append(
            dict(
                name=path.name,
                text=text,
                sec=audio_sec,
                min=audio_min,
                usd=usd,
                jpy=jpy,
                elapsed=elapsed,
                req_id=req_id,
                in_tok=in_tok,
                out_tok=out_tok,
                out_txt=str(out_txt),
            )
        )

        combined_parts.append(text or "")
        if idx < len(targets):
            combined_parts.append(f"\n\n----- ã“ã“ãŒã¤ãªãç›®ã§ã™ï¼ˆ{path.name} ã¨æ¬¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®é–“ï¼‰-----\n\n")

    progress.progress(1.0, text="å®Œäº†")

   
    # ============================================================
    # combined ä¿å­˜ï¼ˆbase_name + _combined ã‚’ job_XX/transcript_combined/ ã«ä¿å­˜ï¼‰
    # ============================================================

    combined_text = "".join(combined_parts)

    # base_name ã‚’ split ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰å¾©å…ƒã™ã‚‹
    # split ãƒ•ã‚¡ã‚¤ãƒ«åã¯ pages/20 ã§
    #   {base_name}_part{i:03d}_{start}-{end}.{ext}
    # ãªã®ã§ stem ã® "_part" ã‚ˆã‚Šå‰ãŒ base_name
    if targets:
        first_stem = targets[0].stem  # ä¾‹: R4ã‚ã‚Šæ–¹æ¤œè¨ä¼š..._part000_000000-000300
        base_name = first_stem.split("_part", 1)[0] if "_part" in first_stem else first_stem
    else:
        base_name = "audio"  # ä¿é™ºï¼ˆé€šå¸¸ã¯ targets ã¯å¿…ãšã‚ã‚‹ï¼‰

    # ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€ï¼šjob_XX ç›´ä¸‹ã« transcript_combined ã‚’ä½œã£ã¦å…¥ã‚Œã‚‹
    combined_dir = picked_job.job_dir / "transcript_combined"
    safe_mkdir(combined_dir)

    combined_name = f"{base_name}_combined.txt"
    combined_txt_path = combined_dir / combined_name

    save_text(combined_txt_path, combined_text or "")
    append_log(job_log_path, f"SAVED combined -> {combined_txt_path}")
    st.success(f"âœ… ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã«ä¿å­˜ã—ã¾ã—ãŸ: {combined_txt_path.name}")
    st.caption(f"ä¿å­˜å…ˆ: {combined_txt_path}")




    with out_area:
        st.markdown("---")
        st.subheader("ğŸ”— é€£çµãƒ†ã‚­ã‚¹ãƒˆï¼ˆå…¨ãƒãƒ£ãƒ³ã‚¯ï¼‰")
        st.text_area("ãƒ†ã‚­ã‚¹ãƒˆï¼ˆé€£çµæ¸ˆã¿ï¼‰", value=combined_text, height=350)

        st.download_button(
            "ğŸ§© é€£çµãƒ†ã‚­ã‚¹ãƒˆï¼ˆ.txtï¼‰ã‚’ï¼ˆãƒ‘ã‚½ã‚³ãƒ³ã«ï¼‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=(combined_text or "").encode("utf-8"),
            file_name="transcripts_combined.txt",
            mime="text/plain",
        )

        total_sec = sum([r["sec"] for r in per_file_results if r["sec"] is not None]) if per_file_results else None
        total_min = sum([r["min"] for r in per_file_results if r["min"] is not None]) if per_file_results else None
        total_usd = sum([r["usd"] for r in per_file_results if r["usd"] is not None]) if per_file_results else None
        total_jpy = sum([r["jpy"] for r in per_file_results if r["jpy"] is not None]) if per_file_results else None

        st.subheader("ğŸ“Š æ–™é‡‘ã®æ¦‚è¦ï¼ˆåˆç®—ï¼‰")
        df_total = pd.DataFrame(
            {
                "ãƒãƒ£ãƒ³ã‚¯æ•°": [len(per_file_results)],
                "åˆè¨ˆå‡¦ç†æ™‚é–“": [f"{total_elapsed:.2f} ç§’"],
                "åˆè¨ˆéŸ³å£°é•·": [f"{total_sec:.1f} ç§’ / {total_min:.2f} åˆ†" if total_sec else "â€”"],
                "åˆè¨ˆæ¦‚ç®— (USD/JPY)": [
                    f"${total_usd:,.6f} / Â¥{total_jpy:,.2f}" if total_usd is not None else "â€”"
                ],
                "ãƒ¢ãƒ‡ãƒ«": [model],
                "å‚™è€ƒ": ["Gemini ã¯ tokens æ¨å®šã«ã‚ˆã‚‹æ¦‚ç®—" if USE_GEMINI else "OpenAI ã¯åˆ†å˜ä¾¡ã«ã‚ˆã‚‹æ¦‚ç®—"],
                "ä¿å­˜å…ˆ(combined)": [str(combined_txt_path)],
            }
        )
        st.table(df_total)

        if per_file_results:
            st.caption("ãƒãƒ£ãƒ³ã‚¯åˆ¥ã‚µãƒãƒªãƒ¼")
            df_each = pd.DataFrame(
                [
                    {
                        "ãƒãƒ£ãƒ³ã‚¯": r["name"],
                        "å‡¦ç†æ™‚é–“(ç§’)": round(r["elapsed"], 2),
                        "éŸ³å£°é•·(åˆ†)": (round(r["min"], 2) if r["min"] is not None else None),
                        "æ¨å®štokens(in/out)": (f"{r['in_tok']}/{r['out_tok']}" if r["in_tok"] is not None else None),
                        "æ¦‚ç®—USD": (round(r["usd"], 6) if r["usd"] is not None else None),
                        "æ¦‚ç®—JPY": (round(r["jpy"], 2) if r["jpy"] is not None else None),
                        "request-id": r["req_id"] or "â€”",
                        "ä¿å­˜å…ˆ": r["out_txt"],
                    }
                    for r in per_file_results
                ]
            )
            st.dataframe(df_each)

    # æ¬¡ãƒšãƒ¼ã‚¸å¼•ãç¶™ãï¼ˆå¿…è¦ãªã‚‰ï¼‰
    st.session_state["transcribed_texts"] = [r["text"] for r in per_file_results]
    st.session_state["transcribed_text"] = combined_text
    st.session_state["picked_job_dir"] = str(picked_job.job_dir)
    st.session_state["combined_txt_path"] = str(combined_txt_path)
